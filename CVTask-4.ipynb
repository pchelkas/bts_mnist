{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computer Vision Internship Program\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Practical Task description:\n",
    "Your task is to write to a pipeline to classify images from MNIST dataset\n",
    "(http://yann.lecun.com/exdb/mnist/)  using Neural Networks!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](mnist.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### To complete this task, you will have to implement the following steps:\n",
    "<br> 1. Download and read the data - 10 points\n",
    "<br> 2. Show how you use augmentation functions. To get the points, visualize the original image vs augmented image using 4 augmentation techniques of your choice - 10 points\n",
    "<br> 3. Implement a Neural Network which classifies given images. You can use any deep learning framework - 10 points\n",
    "<br> 4. Implement a training procedure using your dataloader, augmentation functions and neural network - 10 points\n",
    "<br> 5. Plot loss graph - 10 points\n",
    "<br> 6. Print accuracy of your model on test set -  10 points\n",
    "<br> 7. Show us how your model works! Plot a few input images and corresponding predictions of your model - 10 points\n",
    "\n",
    "##### Main points:\n",
    "<br> *- implement your work in provided jupyter notebook \n",
    "<br> - you can use any framework \n",
    "<br> - we are not too strict about the requirements: if your work corresponds to the task wording, the chances are you will get the full points*\n",
    "\n",
    "\n",
    "If you have any questions, please mail to:\n",
    "olzhas.kabdolov@btsdigital.kz and rustem.burkhanov@btsdigital.kz \n",
    "\n",
    "\n",
    "\n",
    "####  Good luck and have fun!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 1. Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from mlxtend.data import loadlocal_mnist\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import idx2numpy\n",
    "import numpy as np\n",
    "\n",
    "import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "train_images = mnist.train_images()\n",
    "train_labels = mnist.train_labels()\n",
    "\n",
    "test_images = mnist.test_images()\n",
    "test_labels = mnist.test_labels()\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 2. Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss(image):\n",
    "    row,col= image.shape\n",
    "    mean = 0\n",
    "    var = 0.1\n",
    "    sigma = var**0.5\n",
    "    gauss = np.random.normal(mean,sigma,(row,col))\n",
    "    gauss = gauss.reshape(row,col)\n",
    "    noisy = image + gauss\n",
    "    return noisy\n",
    "img = train_images[1, :, :]\n",
    "iMat = gauss(img)\n",
    "plt.imshow(img,'gray')\n",
    "plt.show() \n",
    "plt.imshow(iMat,'gray')\n",
    "plt.show() \n",
    "#display(iMat)\n",
    "#print(gauss(train_images[1, :, :]))\n",
    "flipped = np.fliplr(iMat)\n",
    "plt.imshow(flipped,'gray')\n",
    "plt.show() \n",
    "\n",
    "from scipy import ndimage\n",
    "lx, ly = img.shape\n",
    "crop_face = img[lx // 4: - lx // 4, ly // 4: - ly // 4]\n",
    "plt.imshow(crop_face,'gray')\n",
    "plt.show()\n",
    "\n",
    "blurred_f = ndimage.gaussian_filter(img, 3)\n",
    "plt.imshow(blurred_f,'gray')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 3. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
    "model.add(Dense(128, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 4. Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0],train_images.shape[1] , train_images.shape[2], 1)\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(x=train_images,y=train_labels, epochs=10)\n",
    "\n",
    "test_images = test_images.reshape(test_images.shape[0],test_images.shape[1] , test_images.shape[2], 1)\n",
    "loss, acc = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 5. Loss plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 6. Test set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = test_images.reshape(test_images.shape[0],test_images.shape[1] , test_images.shape[2], 1)\n",
    "loss, acc = model.evaluate(test_images, test_labels)\n",
    "print('accuracy ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 7. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_index = 123\n",
    "plt.imshow(test_images[image_index].reshape(28, 28),cmap='Greys')\n",
    "pred = model.predict(test_images[image_index].reshape(1, 28, 28, 1))\n",
    "print(pred.argmax())\n",
    "\n",
    "image_index = 456\n",
    "plt.imshow(test_images[image_index].reshape(28, 28),cmap='Greys')\n",
    "pred = model.predict(test_images[image_index].reshape(1, 28, 28, 1))\n",
    "print(pred.argmax())\n",
    "\n",
    "image_index = 2222\n",
    "plt.imshow(test_images[image_index].reshape(28, 28),cmap='Greys')\n",
    "pred = model.predict(test_images[image_index].reshape(1, 28, 28, 1))\n",
    "print(pred.argmax())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
